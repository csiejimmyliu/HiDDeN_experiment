{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler,AutoencoderKL\n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "import pprint\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "import utils\n",
    "import csv\n",
    "\n",
    "from model.hidden import Hidden\n",
    "from noise_layers.noiser import Noiser\n",
    "from average_meter import AverageMeter\n",
    "from noise_argparser import NoiseArgParser\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "save_folder='/tmp3/jimmyliu/HiDDeN_experiment/gen_images/test'\n",
    "\n",
    "cap_path='/tmp3/jimmyliu/HiDDeN_experiment/cap_list.json'\n",
    "caps=json.load(open(cap_path))\n",
    "seeds_path='/tmp3/jimmyliu/HiDDeN_experiment/5000_seeds.json'\n",
    "seeds=json.load(open(seeds_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "#model_id=\"stabilityai/stable-diffusion-2-1\"\n",
    "#stable_diffusion_txt2img = StableDiffusionPipeline.from_pretrained(model_id)\n",
    "\n",
    "\n",
    "vae_path='/tmp3/jimmyliu/HiDDeN_experiment/finetune_SD/runs/3_no_w/checkpoints/vae_3'\n",
    "\n",
    "# Use the DPMSolverMultistepScheduler (DPM-Solver++) scheduler here instead\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float32)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "tmpe_vae=AutoencoderKL.from_pretrained(vae_path)\n",
    "pipe.vae.decoder=tmpe_vae.decoder\n",
    "pipe.vae.post_quant_conv=tmpe_vae.post_quant_conv\n",
    "\n",
    "def dummy(images, **kwargs):\n",
    "    return images, False\n",
    "pipe.safety_checker = dummy\n",
    "pipe=pipe.to(device)\n",
    "generator = torch.Generator(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height=256\n",
    "width=256\n",
    "batch_size=2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(seeds)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(len(seeds)/batch_size)):\n",
    "    output=pipe(prompt=caps[i:i+batch_size],height=height,width=width,guidance_scale=3.0,generator = [generator.manual_seed(gen_seed) for gen_seed in seeds[i:i+batch_size]])\n",
    "    for j in range(batch_size):\n",
    "        output.images[j].save(os.path.join(save_folder,f'{i*batch_size+j}.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Emma Watson as a powerful mysterious sorceress, casting lightning magic, detailed clothing, digital painting, hyperrealistic, fantasy, Surrealist, full body, by Stanley Artgerm Lau and Alphonse Mucha, artstation, highly detailed, sharp focus\"\n",
    "#temp = pipe(prompt=[prompt]*num_images,height=height,width=width,latents = latents)\n",
    "temp = pipe(prompt=[prompt]*num_images,height=height,width=width,guidance_scale=3.0,generator = [generator.manual_seed(seeds[i]) for i in range (4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=temp.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=images[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import  transforms\n",
    "from noise_layers.jpeg_compression import rgb2yuv_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=transforms.Compose([\n",
    "            transforms.RandomCrop((512, 512), pad_if_needed=True),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=T(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "img=img.unsqueeze(0)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yuv_img=rgb2yuv_tensor(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yuv_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_message=torch.Tensor([1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.,                                                                                                                                                                                                   \n",
    "        1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.,                                                                                                                                                                                                                 \n",
    "        0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans=wm_decoder(yuv_img.to(device))\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_rounded = ans.detach().cpu().numpy().round().clip(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(decoded_rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitwise_avg_err = np.sum(np.abs(decoded_rounded - fix_message.detach().cpu().numpy())) / fix_message.shape[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
